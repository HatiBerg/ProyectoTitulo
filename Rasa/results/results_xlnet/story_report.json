{
  "action_extract_data": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 6
  },
  "": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 22
  },
  "utter_greet": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6
  },
  "utter_fight": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 4
  },
  "pay_more": {
    "precision": 0.5,
    "recall": 1.0,
    "f1-score": 0.6666666666666666,
    "support": 1
  },
  "request_taxes": {
    "precision": 0.6,
    "recall": 1.0,
    "f1-score": 0.7499999999999999,
    "support": 6
  },
  "[4](amount)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "action_check_amount": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 4
  },
  "pay": {
    "precision": 0.5,
    "recall": 1.0,
    "f1-score": 0.6666666666666666,
    "support": 1
  },
  "utter_inform_taxes": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6
  },
  "[2](amount)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "action_listen": {
    "precision": 0.7,
    "recall": 0.3181818181818182,
    "f1-score": 0.4375,
    "support": 44
  },
  "pay_less": {
    "precision": 0.5,
    "recall": 1.0,
    "f1-score": 0.6666666666666666,
    "support": 2
  },
  "challenge": {
    "precision": 0.5,
    "recall": 1.0,
    "f1-score": 0.6666666666666666,
    "support": 4
  },
  "deny": {
    "precision": 0.4,
    "recall": 1.0,
    "f1-score": 0.5714285714285715,
    "support": 2
  },
  "utter_refuse_payment": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 2
  },
  "greet": {
    "precision": 0.5,
    "recall": 1.0,
    "f1-score": 0.6666666666666666,
    "support": 6
  },
  "[8](amount)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "micro avg": {
    "precision": 0.5977011494252874,
    "recall": 0.43333333333333335,
    "f1-score": 0.5024154589371982,
    "support": 120
  },
  "macro avg": {
    "precision": 0.5111111111111111,
    "recall": 0.6843434343434344,
    "f1-score": 0.5606812169312169,
    "support": 120
  },
  "weighted avg": {
    "precision": 0.485,
    "recall": 0.43333333333333335,
    "f1-score": 0.4185515873015873,
    "support": 120
  },
  "accuracy": 0.43333333333333335,
  "conversation_accuracy": {
    "accuracy": 0.0,
    "correct": 0,
    "with_warnings": 0,
    "total": 6
  }
}