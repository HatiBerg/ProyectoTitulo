{
  "": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 22
  },
  "challenge": {
    "precision": 0.6666666666666666,
    "recall": 1.0,
    "f1-score": 0.8,
    "support": 4
  },
  "request_taxes": {
    "precision": 0.5,
    "recall": 1.0,
    "f1-score": 0.6666666666666666,
    "support": 6
  },
  "[2](amount)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "[8](amount)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "utter_refuse_payment": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 2
  },
  "action_extract_data": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 6
  },
  "utter_inform_taxes": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6
  },
  "action_check_amount": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 4
  },
  "pay": {
    "precision": 0.5,
    "recall": 1.0,
    "f1-score": 0.6666666666666666,
    "support": 1
  },
  "pay_more": {
    "precision": 0.5,
    "recall": 1.0,
    "f1-score": 0.6666666666666666,
    "support": 1
  },
  "pay_less": {
    "precision": 0.5,
    "recall": 1.0,
    "f1-score": 0.6666666666666666,
    "support": 2
  },
  "[4](amount)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "utter_greet": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 6
  },
  "deny": {
    "precision": 0.5,
    "recall": 1.0,
    "f1-score": 0.6666666666666666,
    "support": 2
  },
  "utter_fight": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 4
  },
  "action_listen": {
    "precision": 0.7,
    "recall": 0.3181818181818182,
    "f1-score": 0.4375,
    "support": 44
  },
  "greet": {
    "precision": 0.5,
    "recall": 1.0,
    "f1-score": 0.6666666666666666,
    "support": 6
  },
  "micro avg": {
    "precision": 0.6046511627906976,
    "recall": 0.43333333333333335,
    "f1-score": 0.5048543689320388,
    "support": 120
  },
  "macro avg": {
    "precision": 0.5203703703703703,
    "recall": 0.6843434343434344,
    "f1-score": 0.56875,
    "support": 120
  },
  "weighted avg": {
    "precision": 0.48722222222222217,
    "recall": 0.43333333333333335,
    "f1-score": 0.4204166666666667,
    "support": 120
  },
  "accuracy": 0.43333333333333335,
  "conversation_accuracy": {
    "accuracy": 0.0,
    "correct": 0,
    "with_warnings": 0,
    "total": 6
  }
}